{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e674b27-35d6-4dbd-ad83-191b88a7f8c9",
   "metadata": {},
   "source": [
    "## Use Beautiful Soup to Scrape data from RSS feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b76fe9-eaa4-4f10-bffd-4ca3f443935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a43c419-2d7f-4b2e-b3fc-429308cdee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install lxml to parse xml code in RSS sites\n",
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5a039-0da0-4a26-9f5d-fff9ca81ed1a",
   "metadata": {},
   "source": [
    "The **new_directory_path** below contains all the paths of the historical RSS feeds by date from the Earth Observatory at NASA located here: \n",
    "https://earthobservatory.nasa.gov/feeds/earth-observatory.rss.  \n",
    "\n",
    "In order to run this code, you can download the historical RSS feeds by installing the waybackpack package: https://github.com/jsvine/waybackpack  \n",
    "by running ```pip install waybackpack``` in your terminal.\n",
    "Then, run the command ```waybackpack https://earthobservatory.nasa.gov/feeds/earth-observatory.rss -d [your path] --from-date 2014``` in your terminal, selecting a specific file path on your local computer where you want to download the RSS feed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee9f3af3-7510-45e8-99e4-d9f08bd5debc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path ../../../../Downloads/nasa_climate_rss/.DS_Store/earthobservatory.nasa.gov/feeds/ is not a directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "class XMLAppender(object):\n",
    "    \"\"\"This class appends the separate .xml files from each respective folder.\n",
    "\n",
    "    The functions in this class loop through all of the .xml files from the listed file paths,\n",
    "    parse the data in each file, and append the data into one string so that the content of the\n",
    "    .xml files can be parsed all at once for article titles, links, descriptions, and dates.\n",
    "    \"\"\"\n",
    "    def __init__(self, *filenames):\n",
    "        assert len(filenames) > 0, 'No filenames!'\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def append(self):\n",
    "        \"\"\"Loop through files and read content of each .xml file. Append all content to one \n",
    "        string object.\"\"\"\n",
    "        appended_content = \"\"\n",
    "        for filename in self.filenames:\n",
    "            xml_content = self.read_xml_file(filename)\n",
    "            appended_content += xml_content\n",
    "        return appended_content\n",
    "\n",
    "    def read_xml_file(self, filename):\n",
    "        \"\"\"Open the .xml file and read the content\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading XML file '{filename}': {e}\")\n",
    "            return \"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define the root directory containing date-based subdirectories\n",
    "    root_directory = '../../../../Downloads/nasa_climate_rss/'\n",
    "    branch_directory = 'earthobservatory.nasa.gov/feeds/'\n",
    "    \n",
    "    # Initialize a list to store XML data from all files\n",
    "    all_xml_paths = []\n",
    "    \n",
    "    # Iterate through subdirectories by date\n",
    "    for date_directory in os.listdir(root_directory):\n",
    "        #print(date_directory)\n",
    "        date_directory_path = os.path.join(root_directory, date_directory)\n",
    "        new_directory_path = os.path.join(date_directory_path, branch_directory)\n",
    "    \n",
    "        # Check if the item is a directory\n",
    "        if os.path.isdir(new_directory_path):\n",
    "            # Iterate through XML files within the date directory\n",
    "            for xml_file_name in os.listdir(new_directory_path):\n",
    "                if xml_file_name.endswith('.rss'):\n",
    "                    xml_file_path = os.path.join(new_directory_path, xml_file_name)\n",
    "                    all_xml_paths.append(xml_file_path)\n",
    "        else:\n",
    "            print(f\"Path {new_directory_path} is not a directory.\")\n",
    "\n",
    "    # Create an instance of XMLAppender and append the XML files\n",
    "    appender = XMLAppender(*all_xml_paths)\n",
    "    appended_xml = appender.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0af299f-6433-4e18-b49d-33a9b8f53082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the various attributes of the article\n",
    "def getArticles(articles):\n",
    "    \n",
    "    \"\"\"Loop through article items and parse the title, description, link, and date of\n",
    "    each article, creating a dictionary. Append each dictionary to a list.\"\"\"\n",
    "    \n",
    "    all_articles = []\n",
    "    for article in articles:\n",
    "        article_title = article.find('title').text\n",
    "        article_link = getattr(article.find('link'), 'text', None)\n",
    "        article_desc = getattr(article.find('description'), 'text', None)\n",
    "        article_published = getattr(article.find('pubDate'), 'text', None)\n",
    "        all_articles.append({\n",
    "            'title':article_title,\n",
    "            'link':article_link,\n",
    "            'description':article_desc,\n",
    "            'published':article_published\n",
    "        })\n",
    "    return all_articles\n",
    "\n",
    "# Initialize a list to store parsed results from each <rss> section\n",
    "all_parsed_results = []\n",
    "\n",
    "# Split the XML string into individual <rss> sections\n",
    "rss_sections = appended_xml.split('</rss>')[:-1]\n",
    "\n",
    "# Iterate through each <rss> section and parse it\n",
    "for rss_section in rss_sections:\n",
    "    # Add the opening <rss> tag back to form a valid XML document\n",
    "    rss_section = '<rss>' + rss_section\n",
    "    soup = BeautifulSoup(rss_section, 'xml')\n",
    "\n",
    "    # Parse and process the content within the <rss> section as needed\n",
    "    # Example: Extract items, titles, descriptions, etc.\n",
    "    items = soup.find_all('item')\n",
    "\n",
    "    # Append the parsed result to the list\n",
    "    all_parsed_results.append(items)\n",
    "    \n",
    "\n",
    "# Combine the parsed results from all <rss> sections as needed\n",
    "# Example: Flatten the list, merge, or process the data further\n",
    "combined_results = [item for items in all_parsed_results for item in items]\n",
    "\n",
    "# Print or process the combined results\n",
    "# print(combined_results)\n",
    "\n",
    "# items_2 = combined_results.findAll('item')\n",
    "articles_dict = getArticles(combined_results)\n",
    "#print(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ac4e51c-81b7-43ec-8e48-a6bd722e87d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>Antarctica Eclipsed</td>\n",
       "      <td>https://earthobservatory.nasa.gov/images/14917...</td>\n",
       "      <td>The only total solar eclipse of 2021 was visib...</td>\n",
       "      <td>Tue, 07 Dec 2021 00:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>Spainâ€™s Changing Mediterranean Coastline</td>\n",
       "      <td>https://earthobservatory.nasa.gov/images/14917...</td>\n",
       "      <td>Starved of its sediment supply, the Ebro Delta...</td>\n",
       "      <td>Mon, 06 Dec 2021 00:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>Lake Berryessa</td>\n",
       "      <td>https://earthobservatory.nasa.gov/images/14916...</td>\n",
       "      <td>The reservoir provides water for Napa wine cou...</td>\n",
       "      <td>Sun, 05 Dec 2021 00:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>Mount Michael, Volcano Track or Plume?</td>\n",
       "      <td>https://earthobservatory.nasa.gov/images/14916...</td>\n",
       "      <td>The nearly 1,000-meter-tall volcano in the Sou...</td>\n",
       "      <td>Sat, 04 Dec 2021 00:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>Mapping Marine Microplastics</td>\n",
       "      <td>https://earthobservatory.nasa.gov/images/14916...</td>\n",
       "      <td>Researchers used satellite data to detect and ...</td>\n",
       "      <td>Fri, 03 Dec 2021 00:00:00 -0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "5402                       Antarctica Eclipsed   \n",
       "5403  Spainâ€™s Changing Mediterranean Coastline   \n",
       "5404                            Lake Berryessa   \n",
       "5405    Mount Michael, Volcano Track or Plume?   \n",
       "5406              Mapping Marine Microplastics   \n",
       "\n",
       "                                                   link  \\\n",
       "5402  https://earthobservatory.nasa.gov/images/14917...   \n",
       "5403  https://earthobservatory.nasa.gov/images/14917...   \n",
       "5404  https://earthobservatory.nasa.gov/images/14916...   \n",
       "5405  https://earthobservatory.nasa.gov/images/14916...   \n",
       "5406  https://earthobservatory.nasa.gov/images/14916...   \n",
       "\n",
       "                                            description  \\\n",
       "5402  The only total solar eclipse of 2021 was visib...   \n",
       "5403  Starved of its sediment supply, the Ebro Delta...   \n",
       "5404  The reservoir provides water for Napa wine cou...   \n",
       "5405  The nearly 1,000-meter-tall volcano in the Sou...   \n",
       "5406  Researchers used satellite data to detect and ...   \n",
       "\n",
       "                            published  \n",
       "5402  Tue, 07 Dec 2021 00:00:00 -0500  \n",
       "5403  Mon, 06 Dec 2021 00:00:00 -0500  \n",
       "5404  Sun, 05 Dec 2021 00:00:00 -0500  \n",
       "5405  Sat, 04 Dec 2021 00:00:00 -0500  \n",
       "5406  Fri, 03 Dec 2021 00:00:00 -0500  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(articles_dict)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b1d4c10-009c-46fa-ae6f-eb985de69d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5407, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a9230d-45e3-4bee-9029-8b5c628263c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset= 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8c94e1-525b-4ee2-812f-f9c562cbcfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(752, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb1a2e9-e435-4b3e-b32b-01cdd44a7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv(\"../data/nasa_climate_articles_2020-2023.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c6255-061e-43dd-9944-f1ee1da0115d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
