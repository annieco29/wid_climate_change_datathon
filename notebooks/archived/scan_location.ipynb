{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/bbc_science_and_climate_articles_2010-2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Find location based on list of countries/states within the US "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Extracting US state information from pycountry.\n",
    "# states_info = [{'state_code': subdiv.code.split('-')[1], 'state_name': subdiv.name} for subdiv in pycountry.subdivisions.get(country_code='US')]\n",
    "\n",
    "# # Creating a DataFrame from the list of dictionaries.\n",
    "# df_states = pd.DataFrame(states_info)\n",
    "\n",
    "# # Display the first few rows of the DataFrame.\n",
    "# print(df_states.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a dictionary to hold each column as a separate list\n",
    "# states_as_lists = {col_name: df_states[col_name].tolist() for col_name in df_states.columns}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_code2 = columns_as_lists['alpha_2']\n",
    "# country_code3 = columns_as_lists['alpha_3']\n",
    "# state_name = states_as_lists['state_name']\n",
    "# state_code = states_as_lists['state_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If title/description matches any item in country/state list, create column identifying location that matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pttrn = f\"({'|'.join(country_name)})\"\n",
    "# title_country = df['title'].str.extract(pttrn, flags=re.IGNORECASE, expand=False)\n",
    "# df['title_country'] = title_country[0]\n",
    "\n",
    "# pttrn = f\"({'|'.join(state_name)})\"\n",
    "# df['title_state'] = df['title'].str.extract(pttrn, flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "# pttrn = f\"({'|'.join(country_name)})\"\n",
    "# descrip_country = df['description'].str.extract(pttrn, flags=re.IGNORECASE, expand=False)\n",
    "# df['descrip_country'] = descrip_country[0]\n",
    "\n",
    "# pttrn = f\"({'|'.join(state_name)})\"\n",
    "# df['descrip_state'] = df['description'].str.extract(pttrn, flags=re.IGNORECASE, expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Use NLP to detect location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].astype(str)\n",
    "df['description'] = df['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>published</th>\n",
       "      <th>nlp_title</th>\n",
       "      <th>nlp_descrip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mars rover's wind sensor damaged</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>A sensor on the mast of Nasa's Curiosity rover...</td>\n",
       "      <td>Tue, 21 Aug 2012 20:03:54 GMT</td>\n",
       "      <td>Mars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bugs sunbathe to 'stay healthy'</td>\n",
       "      <td>http://www.bbc.co.uk/nature/19319086</td>\n",
       "      <td>Western boxelder bugs sunbathe to fight off ge...</td>\n",
       "      <td>Wed, 22 Aug 2012 08:08:03 GMT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Star is caught devouring planet</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Astronomers spot evidence of a distant star co...</td>\n",
       "      <td>Tue, 21 Aug 2012 15:55:38 GMT</td>\n",
       "      <td></td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Arctic ice set to hit record low</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Arctic sea ice looks set to reach a record low...</td>\n",
       "      <td>Tue, 21 Aug 2012 10:55:46 GMT</td>\n",
       "      <td>Arctic</td>\n",
       "      <td>Arctic sea, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Shanghai tops 'flood risk list'</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Shanghai is the most vulnerable major city in ...</td>\n",
       "      <td>Tue, 21 Aug 2012 06:58:06 GMT</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20097</th>\n",
       "      <td>20097</td>\n",
       "      <td>193063</td>\n",
       "      <td>Signs of spring 'shifting' in trees</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Scientists say climate change will lead to a s...</td>\n",
       "      <td>Mon, 02 Mar 2015 10:54:47 GMT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20098</th>\n",
       "      <td>20098</td>\n",
       "      <td>193066</td>\n",
       "      <td>SpaceX launches electric satellites</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>US rocket company SpaceX performs a dual-launc...</td>\n",
       "      <td>Mon, 02 Mar 2015 13:33:28 GMT</td>\n",
       "      <td></td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20099</th>\n",
       "      <td>20099</td>\n",
       "      <td>193088</td>\n",
       "      <td>VIDEO: Baby orangutans need new mum</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Staff are hoping two Sumatran orangutans will ...</td>\n",
       "      <td>Mon, 02 Mar 2015 09:47:13 GMT</td>\n",
       "      <td></td>\n",
       "      <td>Dorset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20100</th>\n",
       "      <td>20100</td>\n",
       "      <td>193089</td>\n",
       "      <td>VIDEO: Astronauts brave week's third spacewalk</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Two American astronauts have ventured out on a...</td>\n",
       "      <td>Sun, 01 Mar 2015 17:18:44 GMT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20101</th>\n",
       "      <td>20101</td>\n",
       "      <td>193091</td>\n",
       "      <td>VIDEO: How tidal lagoon power plants work</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>The BBC's Roger Harrabin has been to the site ...</td>\n",
       "      <td>Mon, 02 Mar 2015 07:57:10 GMT</td>\n",
       "      <td></td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20102 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                 0           0   \n",
       "1                 1           1   \n",
       "2                 2           2   \n",
       "3                 3           3   \n",
       "4                 4           4   \n",
       "...             ...         ...   \n",
       "20097         20097      193063   \n",
       "20098         20098      193066   \n",
       "20099         20099      193088   \n",
       "20100         20100      193089   \n",
       "20101         20101      193091   \n",
       "\n",
       "                                                title  \\\n",
       "0                    Mars rover's wind sensor damaged   \n",
       "1                     Bugs sunbathe to 'stay healthy'   \n",
       "2                     Star is caught devouring planet   \n",
       "3                    Arctic ice set to hit record low   \n",
       "4                     Shanghai tops 'flood risk list'   \n",
       "...                                               ...   \n",
       "20097             Signs of spring 'shifting' in trees   \n",
       "20098             SpaceX launches electric satellites   \n",
       "20099             VIDEO: Baby orangutans need new mum   \n",
       "20100  VIDEO: Astronauts brave week's third spacewalk   \n",
       "20101       VIDEO: How tidal lagoon power plants work   \n",
       "\n",
       "                                                    link  \\\n",
       "0      http://www.bbc.co.uk/news/science-environment-...   \n",
       "1                   http://www.bbc.co.uk/nature/19319086   \n",
       "2      http://www.bbc.co.uk/news/science-environment-...   \n",
       "3      http://www.bbc.co.uk/news/science-environment-...   \n",
       "4      http://www.bbc.co.uk/news/science-environment-...   \n",
       "...                                                  ...   \n",
       "20097  http://www.bbc.co.uk/news/science-environment-...   \n",
       "20098  http://www.bbc.co.uk/news/science-environment-...   \n",
       "20099  http://www.bbc.co.uk/news/science-environment-...   \n",
       "20100  http://www.bbc.co.uk/news/science-environment-...   \n",
       "20101  http://www.bbc.co.uk/news/science-environment-...   \n",
       "\n",
       "                                             description  \\\n",
       "0      A sensor on the mast of Nasa's Curiosity rover...   \n",
       "1      Western boxelder bugs sunbathe to fight off ge...   \n",
       "2      Astronomers spot evidence of a distant star co...   \n",
       "3      Arctic sea ice looks set to reach a record low...   \n",
       "4      Shanghai is the most vulnerable major city in ...   \n",
       "...                                                  ...   \n",
       "20097  Scientists say climate change will lead to a s...   \n",
       "20098  US rocket company SpaceX performs a dual-launc...   \n",
       "20099  Staff are hoping two Sumatran orangutans will ...   \n",
       "20100  Two American astronauts have ventured out on a...   \n",
       "20101  The BBC's Roger Harrabin has been to the site ...   \n",
       "\n",
       "                           published nlp_title     nlp_descrip  \n",
       "0      Tue, 21 Aug 2012 20:03:54 GMT      Mars                  \n",
       "1      Wed, 22 Aug 2012 08:08:03 GMT                            \n",
       "2      Tue, 21 Aug 2012 15:55:38 GMT                     Earth  \n",
       "3      Tue, 21 Aug 2012 10:55:46 GMT    Arctic  Arctic sea, US  \n",
       "4      Tue, 21 Aug 2012 06:58:06 GMT  Shanghai        Shanghai  \n",
       "...                              ...       ...             ...  \n",
       "20097  Mon, 02 Mar 2015 10:54:47 GMT                            \n",
       "20098  Mon, 02 Mar 2015 13:33:28 GMT                        US  \n",
       "20099  Mon, 02 Mar 2015 09:47:13 GMT                    Dorset  \n",
       "20100  Sun, 01 Mar 2015 17:18:44 GMT                            \n",
       "20101  Mon, 02 Mar 2015 07:57:10 GMT                        UK  \n",
       "\n",
       "[20102 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Extract location entities\n",
    "#GPE = geopolitical entities (cities/countries)\n",
    "#LOC = non-GPE, mountain ranges/bodies of water\n",
    "\n",
    "def extract_locations(text):\n",
    "    doc = nlp(text)\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
    "    return ', '.join(locations)\n",
    "\n",
    "# Apply the function to the 'Text' column and create a new column 'Locations' with the results\n",
    "df['nlp_title'] = df['title'].apply(extract_locations)\n",
    "df['nlp_descrip'] = df['description'].apply(extract_locations)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save file as a csv file (it takes 7 min to rerun the code)\n",
    "df.to_csv(\"../data/articles_locations_parsed.csv\")\n",
    "\n",
    "#Import file again\n",
    "df = pd.read_csv(\"../data/articles_locations_parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>published</th>\n",
       "      <th>nlp_title</th>\n",
       "      <th>nlp_descrip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mars rover's wind sensor damaged</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>A sensor on the mast of Nasa's Curiosity rover...</td>\n",
       "      <td>Tue, 21 Aug 2012 20:03:54 GMT</td>\n",
       "      <td>Mars</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bugs sunbathe to 'stay healthy'</td>\n",
       "      <td>http://www.bbc.co.uk/nature/19319086</td>\n",
       "      <td>Western boxelder bugs sunbathe to fight off ge...</td>\n",
       "      <td>Wed, 22 Aug 2012 08:08:03 GMT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Star is caught devouring planet</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Astronomers spot evidence of a distant star co...</td>\n",
       "      <td>Tue, 21 Aug 2012 15:55:38 GMT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Arctic ice set to hit record low</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Arctic sea ice looks set to reach a record low...</td>\n",
       "      <td>Tue, 21 Aug 2012 10:55:46 GMT</td>\n",
       "      <td>Arctic</td>\n",
       "      <td>Arctic sea, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Shanghai tops 'flood risk list'</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Shanghai is the most vulnerable major city in ...</td>\n",
       "      <td>Tue, 21 Aug 2012 06:58:06 GMT</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0                             title  \\\n",
       "0             0             0           0  Mars rover's wind sensor damaged   \n",
       "1             1             1           1   Bugs sunbathe to 'stay healthy'   \n",
       "2             2             2           2   Star is caught devouring planet   \n",
       "3             3             3           3  Arctic ice set to hit record low   \n",
       "4             4             4           4   Shanghai tops 'flood risk list'   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://www.bbc.co.uk/news/science-environment-...   \n",
       "1               http://www.bbc.co.uk/nature/19319086   \n",
       "2  http://www.bbc.co.uk/news/science-environment-...   \n",
       "3  http://www.bbc.co.uk/news/science-environment-...   \n",
       "4  http://www.bbc.co.uk/news/science-environment-...   \n",
       "\n",
       "                                         description  \\\n",
       "0  A sensor on the mast of Nasa's Curiosity rover...   \n",
       "1  Western boxelder bugs sunbathe to fight off ge...   \n",
       "2  Astronomers spot evidence of a distant star co...   \n",
       "3  Arctic sea ice looks set to reach a record low...   \n",
       "4  Shanghai is the most vulnerable major city in ...   \n",
       "\n",
       "                       published nlp_title     nlp_descrip  \n",
       "0  Tue, 21 Aug 2012 20:03:54 GMT      Mars             NaN  \n",
       "1  Wed, 22 Aug 2012 08:08:03 GMT       NaN             NaN  \n",
       "2  Tue, 21 Aug 2012 15:55:38 GMT       NaN           Earth  \n",
       "3  Tue, 21 Aug 2012 10:55:46 GMT    Arctic  Arctic sea, US  \n",
       "4  Tue, 21 Aug 2012 06:58:06 GMT  Shanghai        Shanghai  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10,172 out of 20,102 have location data\n",
    "df1 = df[df['nlp_title'].notna() | df['nlp_descrip'].notna()]\n",
    "\n",
    "#4598 titles have location data\n",
    "titles = df1[df1['nlp_title'].notna()]\n",
    "\n",
    "#9,060 descriptions have location data\n",
    "descriptions = df1[df1['nlp_descrip'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import US cities dataframe\n",
    "us_locations = pd.read_csv(\"../data/uscities.csv\")\n",
    "\n",
    "#Use only city, state_name, and county_name\n",
    "city_list = us_locations['city'].unique().tolist()\n",
    "state_list = us_locations['state_name'].unique().tolist()\n",
    "county_list = us_locations['county_name'].unique().tolist()\n",
    "\n",
    "us_list = ['US', 'USA', 'United States of America', 'America']\n",
    "\n",
    "#20,721 unique cities\n",
    "#52 unique states (list includes Puerto Rico & DC)\n",
    "#1,906 unique counties\n",
    "#237,536 unique locations\n",
    "\n",
    "combined_list = city_list + state_list + county_list + us_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/gqvz1z110d948d7cyyfdcr7w0000gn/T/ipykernel_41796/2933158019.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['city_match'] = df1.apply(match_city, axis=1)\n",
      "/var/folders/7l/gqvz1z110d948d7cyyfdcr7w0000gn/T/ipykernel_41796/2933158019.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['state_match'] = df1.apply(match_state, axis=1)\n",
      "/var/folders/7l/gqvz1z110d948d7cyyfdcr7w0000gn/T/ipykernel_41796/2933158019.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['county_match'] = df1.apply(match_county, axis=1)\n"
     ]
    }
   ],
   "source": [
    "#Find titles that match location list\n",
    "\n",
    "def match_city(row):\n",
    "    if row['nlp_title'] in city_list:\n",
    "        return row['nlp_title']\n",
    "    elif row['nlp_descrip'] in city_list:\n",
    "        return row['nlp_descrip']\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def match_state(row):\n",
    "    if row['nlp_title'] in state_list:\n",
    "        return row['nlp_title']\n",
    "    elif row['nlp_descrip'] in state_list:\n",
    "        return row['nlp_descrip']\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def match_county(row):\n",
    "    if row['nlp_title'] in county_list:\n",
    "        return row['nlp_title']\n",
    "    elif row['nlp_descrip'] in county_list:\n",
    "        return row['nlp_descrip']\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "#Create columns for city, state, county match\n",
    "df1['city_match'] = df1.apply(match_city, axis=1)\n",
    "df1['state_match'] = df1.apply(match_state, axis=1)\n",
    "df1['county_match'] = df1.apply(match_county, axis=1)\n",
    "\n",
    "#Not doing US because it's too broad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset if data frame has at least one city_match, state_match, or county_match\n",
    "# df2 = df1[df1['city_match'].notna() | df1['state_match'].notna() | df1['county_match'].notna()]\n",
    "df3 = df1[df1['city_match'].notna()]\n",
    "\n",
    "#2,978 have at least a city match, state match, or county match\n",
    "#2,842 have a city match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2842 entries, 0 to 20096\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0.2  2842 non-null   int64 \n",
      " 1   Unnamed: 0.1  2842 non-null   int64 \n",
      " 2   Unnamed: 0    2842 non-null   int64 \n",
      " 3   title         2842 non-null   object\n",
      " 4   link          2842 non-null   object\n",
      " 5   description   2842 non-null   object\n",
      " 6   published     2842 non-null   object\n",
      " 7   nlp_title     1493 non-null   object\n",
      " 8   nlp_descrip   2535 non-null   object\n",
      " 9   city_match    2842 non-null   object\n",
      " 10  state_match   183 non-null    object\n",
      " 11  county_match  514 non-null    object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 288.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge df3 with lat/long data set\n",
    "df3.head()\n",
    "df4 = df3[['title', 'link', 'description', 'published', 'city_match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>published</th>\n",
       "      <th>city_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mars rover's wind sensor damaged</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>A sensor on the mast of Nasa's Curiosity rover...</td>\n",
       "      <td>Tue, 21 Aug 2012 20:03:54 GMT</td>\n",
       "      <td>Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star is caught devouring planet</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Astronomers spot evidence of a distant star co...</td>\n",
       "      <td>Tue, 21 Aug 2012 15:55:38 GMT</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nasa selects another Mars mission</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Just two weeks after landing its Curiosity rov...</td>\n",
       "      <td>Mon, 20 Aug 2012 20:39:33 GMT</td>\n",
       "      <td>Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nasa's Mars rover zaps first rock</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>Nasa's Curiosity rover deploys its laser instr...</td>\n",
       "      <td>Mon, 20 Aug 2012 11:32:28 GMT</td>\n",
       "      <td>Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Scott's ship found off Greenland</td>\n",
       "      <td>http://www.bbc.co.uk/news/science-environment-...</td>\n",
       "      <td>The wreck of the ship that carried Captain Rob...</td>\n",
       "      <td>Thu, 16 Aug 2012 14:52:21 GMT</td>\n",
       "      <td>Greenland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0    Mars rover's wind sensor damaged   \n",
       "2     Star is caught devouring planet   \n",
       "7   Nasa selects another Mars mission   \n",
       "16  Nasa's Mars rover zaps first rock   \n",
       "19   Scott's ship found off Greenland   \n",
       "\n",
       "                                                 link  \\\n",
       "0   http://www.bbc.co.uk/news/science-environment-...   \n",
       "2   http://www.bbc.co.uk/news/science-environment-...   \n",
       "7   http://www.bbc.co.uk/news/science-environment-...   \n",
       "16  http://www.bbc.co.uk/news/science-environment-...   \n",
       "19  http://www.bbc.co.uk/news/science-environment-...   \n",
       "\n",
       "                                          description  \\\n",
       "0   A sensor on the mast of Nasa's Curiosity rover...   \n",
       "2   Astronomers spot evidence of a distant star co...   \n",
       "7   Just two weeks after landing its Curiosity rov...   \n",
       "16  Nasa's Curiosity rover deploys its laser instr...   \n",
       "19  The wreck of the ship that carried Captain Rob...   \n",
       "\n",
       "                        published city_match  \n",
       "0   Tue, 21 Aug 2012 20:03:54 GMT       Mars  \n",
       "2   Tue, 21 Aug 2012 15:55:38 GMT      Earth  \n",
       "7   Mon, 20 Aug 2012 20:39:33 GMT       Mars  \n",
       "16  Mon, 20 Aug 2012 11:32:28 GMT       Mars  \n",
       "19  Thu, 16 Aug 2012 14:52:21 GMT  Greenland  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30844 locations\n",
    "len(us_locations)\n",
    "\n",
    "#20721 unique locations\n",
    "len(us_locations['city'].unique())\n",
    "\n",
    "#Drop cities that have duplicate keys (same city name but different locality)\n",
    "us_cities_filtered = us_locations[us_locations['city'].duplicated(keep=False) == False]\n",
    "\n",
    "#16,807 cities that have unique names\n",
    "\n",
    "#Keep important columns\n",
    "us_cities_filtered = us_cities_filtered[['city', 'state_name', 'county_name', 'lat', 'lng']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>Queens</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Cook</td>\n",
       "      <td>41.8375</td>\n",
       "      <td>-87.6866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>King</td>\n",
       "      <td>47.6211</td>\n",
       "      <td>-122.3244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>37.7558</td>\n",
       "      <td>-122.4449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Queens</td>\n",
       "      <td>New York</td>\n",
       "      <td>Queens</td>\n",
       "      <td>40.7498</td>\n",
       "      <td>-73.7976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  state_name    county_name      lat       lng\n",
       "0        New York    New York         Queens  40.6943  -73.9249\n",
       "2         Chicago    Illinois           Cook  41.8375  -87.6866\n",
       "12        Seattle  Washington           King  47.6211 -122.3244\n",
       "13  San Francisco  California  San Francisco  37.7558 -122.4449\n",
       "19         Queens    New York         Queens  40.7498  -73.7976"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename df4 column\n",
    "df4 = df4.rename(columns = {'city_match':'city'})\n",
    "\n",
    "#Merge df4 with us_cities_filtered based on \n",
    "df5 = df4.merge(us_cities_filtered, on='city', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove if city matches a country name or if it's a planet name (there are articles with Mars and Earth as a location)\n",
    "# Creating a list of dictionaries, where each dictionary contains information about a country.\n",
    "countries_info = []\n",
    "for country in pycountry.countries:\n",
    "    countries_info.append({\n",
    "        'country_name': country.name,\n",
    "        'alpha_2': country.alpha_2,\n",
    "        'alpha_3': country.alpha_3,\n",
    "        'official_name': getattr(country, 'official_name', country.name)  # Some countries might not have an official_name attribute.\n",
    "    })\n",
    "\n",
    "# Creating a DataFrame from the list of dictionaries.\n",
    "df_countries = pd.DataFrame(countries_info)\n",
    "\n",
    "countries_as_lists = {col_name: df_countries[col_name].tolist() for col_name in df_countries.columns}\n",
    "\n",
    "country_name = countries_as_lists['country_name']\n",
    "\n",
    "planet_name = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5[~df5['city'].isin(country_name)]\n",
    "final_df = df6[~df6['city'].isin(planet_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Isle', 'England', 'Rugby', 'Sardinia', 'Tripoli', 'Russia',\n",
       "       'Edinburgh', 'Oklahoma', 'Stirling', 'North Wales', 'Mount Etna',\n",
       "       'Gulf', 'North Sea', 'New York', 'Queensland', 'North Pole',\n",
       "       'Farmland', 'Chicago', 'Bolivia', 'Hereford', 'New Orleans',\n",
       "       'Northumberland', 'Perth', 'Munich', 'Amazonia', 'Sun',\n",
       "       'Johannesburg', 'Belfast', 'Birdsong', 'Suffolk', 'Patagonia',\n",
       "       'Seattle', 'Island', 'Santiago', 'Tennessee', 'Herculaneum',\n",
       "       'Truro', 'Cape Canaveral', 'San Francisco', 'San Cristobal',\n",
       "       'Brussels', 'Hampshire', 'Everest', 'Wimbledon', 'Louisiana',\n",
       "       'Gulf Stream', 'Zephyr', 'Midwest', 'Brisbane', 'Donegal',\n",
       "       'Dumfries', 'Maine', 'Edmonton', 'North East', 'Whitehaven',\n",
       "       'Nile', 'Carmichael', 'Virgin', 'Amanda', 'Marine', 'Tulsa',\n",
       "       'Baird', 'Ohio', 'Theresa', 'West End'], dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['city'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
